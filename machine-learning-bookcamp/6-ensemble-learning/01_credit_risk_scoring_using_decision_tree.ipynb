{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM4TalLK23gYbIUEGqogWIj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/machine-learning-research-and-practice/blob/main/machine-learning-bookcamp/6-ensemble-learning/01_credit_risk_scoring_using_decision_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Credit risk scoring project: Decision tree"
      ],
      "metadata": {
        "id": "nKiw-jHgceh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagine that we work at a bank. When we receive a loan application, we need to make\n",
        "sure that if we give the money, the customer will be able to pay it back. Every application\n",
        "carries a risk of default — the failure to return the money.\n",
        "\n",
        "Credit risk scoring is a binary classification problem: the target is positive (“1”) if the\n",
        "customer defaults and negative (“0”) otherwise.\n",
        "\n",
        "We will use machine learning to calculate the risk of\n",
        "default. The plan for the project is the following:\n",
        "\n",
        "* We will train decision tree model for predicting the probability\n",
        "of default.\n",
        "* Then we combine multiple decision trees into one model — a random forest.\n",
        "* Finally, we explore a different way of combining decision trees — gradient\n",
        "boosting(XGBoost)."
      ],
      "metadata": {
        "id": "n-ZdMvNtchEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "8MqwP3Hzc1Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle \n",
        "import requests\n",
        "\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "vpCaukoZc2bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "bA6YUwP1c_KM",
        "outputId": "9db8e997-694e-4d4c-8182-05cfe929b9ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# content/gdrive/My Drive/Kaggle is the path where kaggle.json is  present in the Google Drive\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/kaggle-keys\""
      ],
      "metadata": {
        "id": "Khw2AeAidQ7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# download dataset from kaggle> URL: https://www.kaggle.com/blastchar/telco-customer-churn\n",
        "kaggle datasets download -d blastchar/telco-customer-churn\n",
        "\n",
        "unzip -qq telco-customer-churn.zip\n",
        "rm -rf telco-customer-churn.zip"
      ],
      "metadata": {
        "id": "8EuMmwDKdXEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "JKpNUL22eB1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let’s read our dataset\n",
        "data_df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "len(data_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US7ds406eEwl",
        "outputId": "a8c83fe0-1bad-45b8-8a15-ca71d1b4a22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7043"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# so, let's set the missing values to zero\n",
        "data_df[\"TotalCharges\"] = pd.to_numeric(data_df.TotalCharges, errors=\"coerce\")\n",
        "data_df[\"TotalCharges\"] = data_df[\"TotalCharges\"].fillna(0)"
      ],
      "metadata": {
        "id": "gJ6bAyO3BM0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s make the column names uniform by lowercasing everything and replacing spaces with underscores\n",
        "data_df.columns = data_df.columns.str.lower().str.replace(\" \", \"_\")\n",
        "string_columns = list(data_df.dtypes[data_df.dtypes == \"object\"].index)\n",
        "\n",
        "for col in string_columns:\n",
        "  data_df[col] = data_df[col].str.lower().str.replace(\" \", \"_\")"
      ],
      "metadata": {
        "id": "8RxmSWRRCIIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# so, let’s convert the target variable to numbers\n",
        "data_df.churn = (data_df.churn == \"yes\").astype(int)"
      ],
      "metadata": {
        "id": "pqq7tWy_DBFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split such that 80% of the data goes to the train set and the remaining 20% goes to the test set.\n",
        "df_train_full, df_test = train_test_split(data_df, test_size=0.2, random_state=1)\n",
        "\n",
        "df_train_full = df_train_full.reset_index(drop=True)\n",
        "df_test = df_test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "CPM1VXhp2jmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's split it one more time into train and validation\n",
        "df_train, df_val = train_test_split(df_train_full, test_size=0.33, random_state=11)\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "jMF2Y3fq609Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes the column with the target variable, churn, and saves it outside the dataframe\n",
        "y_train = df_train.churn.values\n",
        "y_val = df_val.churn.values"
      ],
      "metadata": {
        "id": "Q0pd3UeC7uwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deletes the churn columns\n",
        "del df_train[\"churn\"]\n",
        "del df_val[\"churn\"]"
      ],
      "metadata": {
        "id": "n_M-124_78Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's create two lists for categorical and numerical variables\n",
        "categorical_cols = [\n",
        "  'gender', 'seniorcitizen', 'partner', 'dependents',\n",
        "  'phoneservice', 'multiplelines', 'internetservice',\n",
        "  'onlinesecurity', 'onlinebackup', 'deviceprotection',\n",
        "  'techsupport', 'streamingtv', 'streamingmovies',\n",
        "  'contract', 'paperlessbilling', 'paymentmethod'\n",
        "]\n",
        "\n",
        "numerical_cols = ['tenure', 'monthlycharges', 'totalcharges']"
      ],
      "metadata": {
        "id": "-KciNwlaWnDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "ihUFw9Vx3ZZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(df, y, C):\n",
        "  # Applies one-hot encoding\n",
        "  cat = df[categorical_cols + numerical_cols].to_dict(orient=\"records\")\n",
        "\n",
        "  dv = DictVectorizer(sparse=False)\n",
        "  dv.fit(cat)\n",
        "\n",
        "  X = dv.transform(cat)\n",
        "\n",
        "  model = LogisticRegression(solver=\"liblinear\", C=C)\n",
        "  model.fit(X, y)\n",
        "  return dv, model\n",
        "\n",
        "def predict(df, dv, model):\n",
        "  cat = df[categorical_cols + numerical_cols].to_dict(orient=\"records\")\n",
        "\n",
        "  X = dv.transform(cat)\n",
        "\n",
        "  y_pred = model.predict_proba(X)[:, 1]\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "t_5IDm2bYrEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df_train_full.churn.values\n",
        "y_test = df_test.churn.values\n",
        "\n",
        "# Trains the model and makes predictions\n",
        "dv, model = train(df_train_full, y_train, C=0.5)\n",
        "y_pred = predict(df_test, dv, model)\n",
        "\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f\"auc={auc:.3f}\")"
      ],
      "metadata": {
        "id": "XQtBbsFDZuai",
        "outputId": "d362cd05-d023-4d71-937e-467e5a30a921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc=0.858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prediction"
      ],
      "metadata": {
        "id": "0AXuIRyO3bzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s use this model to calculate the probability of churning."
      ],
      "metadata": {
        "id": "UTbniSX-3rkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customer = {\n",
        "    'customerid': '8879-zkjof',\n",
        "    'gender': 'female',\n",
        "    'seniorcitizen': 0,\n",
        "    'partner': 'no',\n",
        "    'dependents': 'no',\n",
        "    'tenure': 41,\n",
        "    'phoneservice': 'yes',\n",
        "    'multiplelines': 'no',\n",
        "    'internetservice': 'dsl',\n",
        "    'onlinesecurity': 'yes',\n",
        "    'onlinebackup': 'no',\n",
        "    'deviceprotection': 'yes',\n",
        "    'techsupport': 'yes',\n",
        "    'streamingtv': 'yes',\n",
        "    'streamingmovies': 'yes',\n",
        "    'contract': 'one_year',\n",
        "    'paperlessbilling': 'yes',\n",
        "    'paymentmethod': 'bank_transfer_(automatic)',\n",
        "    'monthlycharges': 79.85,\n",
        "    'totalcharges': 3320.75\n",
        "}\n",
        "\n",
        "df = pd.DataFrame([customer])\n",
        "y_pred = predict(df, dv, model)\n",
        "y_pred[0]"
      ],
      "metadata": {
        "id": "4icADesd3dSw",
        "outputId": "463afad7-935e-4335-f019-0e7313528c55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.061875685940780745"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single(customer, dv, model):\n",
        "  X = dv.transform([customer])\n",
        "  y_pred = model.predict_proba(X)[:, 1]\n",
        "  return y_pred[0]"
      ],
      "metadata": {
        "id": "ajk8TndtcVx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_single(customer, dv, model)"
      ],
      "metadata": {
        "id": "DmtOpgd-c9X0",
        "outputId": "182c075d-e570-4914-df0d-7a39d6ec60b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.061875685940780745"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save model"
      ],
      "metadata": {
        "id": "sHdMTm7JdQJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's save the model using Pickle module\n",
        "with open(\"churn-model.bin\", \"wb\") as f_out:\n",
        "  pickle.dump(model, f_out)"
      ],
      "metadata": {
        "id": "iFdNnY-5dSgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our case, however, saving just the model is not enough: we also have a DictVectorizer that we “trained” together with the model. \n",
        "\n",
        "We need to save both."
      ],
      "metadata": {
        "id": "r8kFvIv52YMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's save the model using Pickle module\n",
        "with open(\"churn-model.bin\", \"wb\") as f_out:\n",
        "  pickle.dump((dv, model), f_out)"
      ],
      "metadata": {
        "id": "3EnFDNWw2ayr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load model"
      ],
      "metadata": {
        "id": "SiRenZ1V5GQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's load the saved model\n",
        "with open(\"churn-model.bin\", \"rb\") as f_in:\n",
        "  dv, model = pickle.load(f_in)"
      ],
      "metadata": {
        "id": "-oOEC2EC3ARn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And apply it\n",
        "prediction = predict_single(customer, dv, model)\n",
        "print(f\"prediction: {prediction:.3f}\")"
      ],
      "metadata": {
        "id": "bwZJ1Wvv5Rek",
        "outputId": "fa0f254d-2e3a-4a9a-b28c-f99bad1151b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction: 0.062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let’s display the results\n",
        "if prediction >= 0.5:\n",
        "  print(\"verdict: Churn\")\n",
        "else:\n",
        "  print(\"verdict: No Churn\")"
      ],
      "metadata": {
        "id": "gvYRjBTp6hvO",
        "outputId": "49e547c0-415b-4599-e038-a93876770cc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verdict: No Churn\n"
          ]
        }
      ]
    }
  ]
}