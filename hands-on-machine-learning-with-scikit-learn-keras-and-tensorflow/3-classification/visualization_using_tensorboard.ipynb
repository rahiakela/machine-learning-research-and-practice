{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "visualization-using-tensorboard.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow/blob/10-introduction-to-artificial-neural-networks-with-keras/visualization_using_tensorboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r_YFTdU-h8Y",
        "colab_type": "text"
      },
      "source": [
        "# Using TensorBoard for Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd5fFvHJ-10_",
        "colab_type": "text"
      },
      "source": [
        "TensorBoard is a great interactive visualization tool that you can use to view the learning curves during training, compare learning curves between multiple runs, visualize the computation graph, analyze training statistics, view images generated by your model, visualize complex multidimensional data projected down to 3D and automatically clustered for you, and more! This tool is installed automatically when you install TensorFlow, so you already have it.\n",
        "\n",
        "To use it, you must modify your program so that it outputs the data you want to visualize to special binary log files called event files . Each binary data record is called a summary . The TensorBoard server will monitor the log directory, and it will automatically pick up the changes and update the visualizations: this allows you to visualize live data (with a short delay), such as the learning curves during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io8aKlSM_Rcm",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28VuI2oI_S0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7d67bc33-06d8-4c50-d493-14a7a86526d9"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omz4Fwp__YMz",
        "colab_type": "text"
      },
      "source": [
        "## Load database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F3XZp_O_YsL",
        "colab_type": "text"
      },
      "source": [
        "Let’s switch to the California housing problem and tackle it using a regression neural network. For simplicity, we will use Scikit-Learn’s fetch_california_housing() function to load the data.\n",
        "\n",
        "After loading the data, we split it into a training set, a validation set, and a test set, and we scale all the features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlemKnoB_V5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "653ac611-fae4-4cc1-bbab-d2515d8998d9"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# load dataset\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "# split dataset into traing and test set \n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "\n",
        "# prepare validation set\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "# scale all the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve-Lfyy1_dvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8bg_5o6_0hn",
        "colab_type": "text"
      },
      "source": [
        "Let’s start by defining the root log directory we will use for our TensorBoard logs, plus a small function that will generate a subdirectory path based on the current date and time so that it’s different at every run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA42lC43_gLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "root_logdir = os.path.join(os.curdir, 'my_logs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKn5HY8b_-Rg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "516fdd68-be71-445d-e1cd-ac19bb1270fa"
      },
      "source": [
        "def get_run_logdir():\n",
        "  import time\n",
        "  run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
        "  return os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "run_logdir "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./my_logs/run_2019_11_26-09_19_14'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbs33lgRCKAX",
        "colab_type": "text"
      },
      "source": [
        "## Build the model with TensorBoard callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I7cy4ULAfby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkTxTIepEn4M",
        "colab_type": "text"
      },
      "source": [
        "## Running TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7o4cQrcEr93",
        "colab_type": "text"
      },
      "source": [
        "To start the TensorBoard server, one option is to open a terminal, if needed activate the virtualenv where you installed TensorBoard, go to this notebook's directory, then type:\n",
        "\n",
        "$ tensorboard --logdir=./my_logs --port=6006\n",
        "You can then open your web browser to localhost:6006 and use TensorBoard. Once you are done, press Ctrl-C in the terminal window, this will shutdown the TensorBoard server.\n",
        "\n",
        "Alternatively, you can use TensorBoard directly within Jupyter, by running the following commands. The first line loads the TensorBoard extension, and the second line starts a TensorBoard server on port 6006 (unless it is already started) and connects to it:\n",
        "\n",
        "reference: \n",
        "https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/\n",
        "\n",
        "https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvpc8Z7rEzW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_DIR = '/tmp/log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5MryT5KE2AE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "7fa88902-9bce-47df-df5b-db38006df720"
      },
      "source": [
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-26 10:11:48--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.235.200.97, 52.3.53.115, 3.221.56.183, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.235.200.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  12%[=>                  ]   1.59M  7.71MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  37.1MB/s    in 0.4s    \n",
            "\n",
            "2019-11-26 10:11:48 (37.1 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ2jDoBvMl5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeFN0wx-MpYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "726da6c8-462a-4365-a57c-306bb7b1f473"
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://4f89514d.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POJFce5JMzp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca73b3e9-2a75-4aaf-a4e2-9a60456c0a43"
      },
      "source": [
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/30\n",
            "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3727 - val_loss: 0.3587\n",
            "Epoch 2/30\n",
            "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3713 - val_loss: 0.3479\n",
            "Epoch 3/30\n",
            "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3698 - val_loss: 0.3481\n",
            "Epoch 4/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3682 - val_loss: 0.3455\n",
            "Epoch 5/30\n",
            "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3669 - val_loss: 0.3483\n",
            "Epoch 6/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3655 - val_loss: 0.3583\n",
            "Epoch 7/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3641 - val_loss: 0.3423\n",
            "Epoch 8/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3633 - val_loss: 0.3738\n",
            "Epoch 9/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3620 - val_loss: 0.3512\n",
            "Epoch 10/30\n",
            "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3610 - val_loss: 0.3433\n",
            "Epoch 11/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3597 - val_loss: 0.3561\n",
            "Epoch 12/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3587 - val_loss: 0.3398\n",
            "Epoch 13/30\n",
            "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3577 - val_loss: 0.3637\n",
            "Epoch 14/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3570 - val_loss: 0.3394\n",
            "Epoch 15/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3557 - val_loss: 0.3738\n",
            "Epoch 16/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3550 - val_loss: 0.3348\n",
            "Epoch 17/30\n",
            "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3543 - val_loss: 0.3736\n",
            "Epoch 18/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3532 - val_loss: 0.3521\n",
            "Epoch 19/30\n",
            "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3526 - val_loss: 0.3412\n",
            "Epoch 20/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3519 - val_loss: 0.3482\n",
            "Epoch 21/30\n",
            "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3513 - val_loss: 0.3388\n",
            "Epoch 22/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3505 - val_loss: 0.3502\n",
            "Epoch 23/30\n",
            "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3497 - val_loss: 0.3505\n",
            "Epoch 24/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3493 - val_loss: 0.3321\n",
            "Epoch 25/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3485 - val_loss: 0.3424\n",
            "Epoch 26/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3477 - val_loss: 0.3827\n",
            "Epoch 27/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3475 - val_loss: 0.3371\n",
            "Epoch 28/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3465 - val_loss: 0.3546\n",
            "Epoch 29/30\n",
            "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3460 - val_loss: 0.3630\n",
            "Epoch 30/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3455 - val_loss: 0.3308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVy8u8gxDnue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Fya1WKQqtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])    \n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.05))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlVn3o0yQspz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89423b42-9630-4220-f5cf-b76e29217f0b"
      },
      "source": [
        "run_logdir2 = get_run_logdir()\n",
        "run_logdir2"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./my_logs/run_2019_11_26-10_30_34'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEhgurmzQ0PM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43e5fdea-3e40-4f48-b1ed-82a6a3a67f57"
      },
      "source": [
        "\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid),\n",
        "                    callbacks=[tensorboard_cb])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/30\n",
            "11610/11610 [==============================] - 1s 86us/sample - loss: 0.7860 - val_loss: 3.9608\n",
            "Epoch 2/30\n",
            "11610/11610 [==============================] - 1s 59us/sample - loss: 0.4406 - val_loss: 19.3301\n",
            "Epoch 3/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3807 - val_loss: 1.9304\n",
            "Epoch 4/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.4081 - val_loss: 0.3692\n",
            "Epoch 5/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3796 - val_loss: 0.3266\n",
            "Epoch 6/30\n",
            "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3664 - val_loss: 0.3184\n",
            "Epoch 7/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3655 - val_loss: 0.3169\n",
            "Epoch 8/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3443 - val_loss: 0.3244\n",
            "Epoch 9/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3387 - val_loss: 0.3121\n",
            "Epoch 10/30\n",
            "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3369 - val_loss: 0.3396\n",
            "Epoch 11/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3580 - val_loss: 0.3517\n",
            "Epoch 12/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3431 - val_loss: 0.3335\n",
            "Epoch 13/30\n",
            "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3306 - val_loss: 0.3237\n",
            "Epoch 14/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3236 - val_loss: 0.3274\n",
            "Epoch 15/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3181 - val_loss: 0.3128\n",
            "Epoch 16/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3175 - val_loss: 0.3028\n",
            "Epoch 17/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3130 - val_loss: 0.2991\n",
            "Epoch 18/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3111 - val_loss: 0.3055\n",
            "Epoch 19/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3099 - val_loss: 0.2939\n",
            "Epoch 20/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3098 - val_loss: 0.2968\n",
            "Epoch 21/30\n",
            "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3063 - val_loss: 0.3056\n",
            "Epoch 22/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3048 - val_loss: 0.2926\n",
            "Epoch 23/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.2997 - val_loss: 0.3007\n",
            "Epoch 24/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3002 - val_loss: 0.2968\n",
            "Epoch 25/30\n",
            "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3028 - val_loss: 0.2879\n",
            "Epoch 26/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.2946 - val_loss: 0.2915\n",
            "Epoch 27/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.2955 - val_loss: 0.2907\n",
            "Epoch 28/30\n",
            "11610/11610 [==============================] - 1s 56us/sample - loss: 0.2902 - val_loss: 0.2991\n",
            "Epoch 29/30\n",
            "11610/11610 [==============================] - 1s 60us/sample - loss: 0.2932 - val_loss: 1.1143\n",
            "Epoch 30/30\n",
            "11610/11610 [==============================] - 1s 57us/sample - loss: 0.2898 - val_loss: 0.2817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGpIHh72Q7Ip",
        "colab_type": "text"
      },
      "source": [
        "Notice how TensorBoard now sees two runs, and you can compare the learning curves.\n",
        "\n",
        "Check out the other available logging options:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6MeYrQrQ7wJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "b8879b9c-2735-4e96-9b0a-602a977faa19"
      },
      "source": [
        "help(keras.callbacks.TensorBoard.__init__)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function __init__ in module tensorflow.python.keras.callbacks:\n",
            "\n",
            "__init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
            "    Initialize self.  See help(type(self)) for accurate signature.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DgKnQYhQ6IZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}