{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "saving-and-restoring-model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow/blob/10-introduction-to-artificial-neural-networks-with-keras/saving_and_restoring_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2kIv_AuRFdn",
        "colab_type": "text"
      },
      "source": [
        "# Saving and Restoring a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhNEBAe2RJDb",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmP50bWsRPfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b3d83d53-bc95-4c75-ba5c-26a6e7a10896"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7egiXGFeRXgC",
        "colab_type": "text"
      },
      "source": [
        "## Load database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s8iglKpRYDy",
        "colab_type": "text"
      },
      "source": [
        "Let’s switch to the California housing problem and tackle it using a regression neural network. For simplicity, we will use Scikit-Learn’s fetch_california_housing() function to load the data.\n",
        "\n",
        "After loading the data, we split it into a training set, a validation set, and a test set, and we scale all the features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gzul4AWkRfSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "db5e27fe-23a3-4c5f-fd7d-4a2908a27530"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# load dataset\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "# split dataset into traing and test set \n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "\n",
        "# prepare validation set\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "# scale all the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4DHkrHkRh1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3F4doEKRiS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQCrUPUmRwjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "f8b6b7f6-bc6f-4528-c621-731894ede3b9"
      },
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "mse_test = model.evaluate(X_test, y_test, verbose=0)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/10\n",
            "11610/11610 [==============================] - 1s 95us/sample - loss: 0.3222 - val_loss: 0.3255\n",
            "Epoch 2/10\n",
            "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3223 - val_loss: 0.3073\n",
            "Epoch 3/10\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3218 - val_loss: 0.3158\n",
            "Epoch 4/10\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3215 - val_loss: 0.3076\n",
            "Epoch 5/10\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3212 - val_loss: 0.3088\n",
            "Epoch 6/10\n",
            "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3210 - val_loss: 0.3380\n",
            "Epoch 7/10\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3206 - val_loss: 0.3251\n",
            "Epoch 8/10\n",
            "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3207 - val_loss: 0.4134\n",
            "Epoch 9/10\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3206 - val_loss: 0.3126\n",
            "Epoch 10/10\n",
            "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3198 - val_loss: 0.3240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnsp0C6wR28i",
        "colab_type": "text"
      },
      "source": [
        "## Saving and Restoring a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Buqtv4muR4JG",
        "colab_type": "text"
      },
      "source": [
        "When using the Sequential API or the Functional API, saving a trained Keras model is as simple as it gets.\n",
        "\n",
        "Keras will use the HDF5 format to save both the model’s architecture (including every layer’s hyperparameters) and the values of all the model parameters for every layer(connection weights and biases). It also saves the optimizer (including its hyperparameters and any state it may have)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz1N673aV-0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('my_keras_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32BSy5QVXany",
        "colab_type": "text"
      },
      "source": [
        "You will typically have a script that trains a model and saves it, and one or more scripts (or web services) that load the model and use it to make predictions. Loading the model is just as easy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xledhPRfW-j8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = keras.models.load_model('my_keras_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfJTseJLXjeQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "895e75a3-fe17-4144-e47a-4bd6c3d0d6e2"
      },
      "source": [
        "# make prediction\n",
        "X_new = X_test[:3]\n",
        "model_1.predict(X_new)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5490972],\n",
              "       [1.6584849],\n",
              "       [3.0271606]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "917Rri4BeEFb",
        "colab_type": "text"
      },
      "source": [
        "This will work when using the Sequential API or the Functional API, but unfortunately not when using model subclassing. You can use save_weights() and load_weights() to at least save and restore the model parameters, but you will need to save and restore everything else yourself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEzZ88F-Xugq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1.save_weights('my_keras_weights.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRe02eNeedho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b764a804-122d-4f68-98ef-ab5320ee3d1a"
      },
      "source": [
        "model_1.load_weights('my_keras_weights.ckpt')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1a882a99e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6xs5xc4fzOx",
        "colab_type": "text"
      },
      "source": [
        "But how can you tell the fit() method to save checkpoints? Use callbacks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tZ8noUCgEmE",
        "colab_type": "text"
      },
      "source": [
        "## Using Callbacks during Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSCIWtA1gFo0",
        "colab_type": "text"
      },
      "source": [
        "The fit() method accepts a callbacks argument that lets you specify a list of objects that Keras will call at the start and end of training, at the start and end of each epoch, and even before and after processing each batch. \n",
        "\n",
        "For example, the ModelCheckpoint callback saves checkpoints of your model at regular intervals during training, by default at the end of each epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFBrG3oUeeWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb2vV9mmgWD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfl2QHOygYNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ERLOb8shzaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwyPOia6hzw8",
        "colab_type": "text"
      },
      "source": [
        "Moreover, if you use a validation set during training, you can set save_best_only=True when creating the ModelCheckpoint . In this case, it will only save your model when its performance on the validation set is the best so far. This way, you do not need to worry about training for too long and overfitting the training set: simply restore the last model saved after training, and this will be the best model on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGqm-6nZgcwD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "33326acb-45a1-43d1-dcd0-da341918ec27"
      },
      "source": [
        "history_1 = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid,y_valid), callbacks=[checkpoint_cb])\n",
        "model = keras.models.load_model('my_keras_model.h5')  # rollback to best model\n",
        "mse_test = model.evaluate(X_test, y_test, verbose=0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/10\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3369 - val_loss: 0.3693\n",
            "Epoch 2/10\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3369 - val_loss: 0.3194\n",
            "Epoch 3/10\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3363 - val_loss: 0.3390\n",
            "Epoch 4/10\n",
            "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3359 - val_loss: 0.3212\n",
            "Epoch 5/10\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3355 - val_loss: 0.3211\n",
            "Epoch 6/10\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3351 - val_loss: 0.3529\n",
            "Epoch 7/10\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3347 - val_loss: 0.3228\n",
            "Epoch 8/10\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3345 - val_loss: 0.4017\n",
            "Epoch 9/10\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3343 - val_loss: 0.3182\n",
            "Epoch 10/10\n",
            "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3336 - val_loss: 0.3231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lIK86Vijth-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1941ec9f-a692-4b69-cd86-f1a74343ca74"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "plt.plot(pd.DataFrame(history_1.history))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGA_lV6OhntM",
        "colab_type": "text"
      },
      "source": [
        "Another way to implement early stopping is to simply use the EarlyStopping callback. It will interrupt training when it measures no progress on the validation set for a number of epochs (defined by the patience argument), and it will optionally roll back to the best model. You can combine both callbacks to save checkpoints of your model (in case your computer crashes) and interrupt training early when there is no more progress (to avoid wasting time and resources):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El475gOMhPxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0ktq28zi8xt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47b0163f-929a-4ba3-9eee-c0317e4d654c"
      },
      "source": [
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "history_2 = model.fit(X_train, y_train, epochs=100, validation_data=(X_valid,y_valid), callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "mse_test = model.evaluate(X_test, y_test, verbose=0)    "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/100\n",
            "11610/11610 [==============================] - 1s 77us/sample - loss: 0.3334 - val_loss: 0.3613\n",
            "Epoch 2/100\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3335 - val_loss: 0.3169\n",
            "Epoch 3/100\n",
            "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3330 - val_loss: 0.3355\n",
            "Epoch 4/100\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3326 - val_loss: 0.3176\n",
            "Epoch 5/100\n",
            "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3322 - val_loss: 0.3187\n",
            "Epoch 6/100\n",
            "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3319 - val_loss: 0.3497\n",
            "Epoch 7/100\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3314 - val_loss: 0.3228\n",
            "Epoch 8/100\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3314 - val_loss: 0.4040\n",
            "Epoch 9/100\n",
            "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3312 - val_loss: 0.3148\n",
            "Epoch 10/100\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3304 - val_loss: 0.3213\n",
            "Epoch 11/100\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3300 - val_loss: 0.3322\n",
            "Epoch 12/100\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3297 - val_loss: 0.3147\n",
            "Epoch 13/100\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3293 - val_loss: 0.3584\n",
            "Epoch 14/100\n",
            "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3292 - val_loss: 0.3133\n",
            "Epoch 15/100\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3285 - val_loss: 0.3887\n",
            "Epoch 16/100\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3286 - val_loss: 0.3387\n",
            "Epoch 17/100\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3284 - val_loss: 0.4218\n",
            "Epoch 18/100\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3281 - val_loss: 0.3137\n",
            "Epoch 19/100\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3275 - val_loss: 0.3530\n",
            "Epoch 20/100\n",
            "11610/11610 [==============================] - 1s 70us/sample - loss: 0.3274 - val_loss: 0.3115\n",
            "Epoch 21/100\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3269 - val_loss: 0.3415\n",
            "Epoch 22/100\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3267 - val_loss: 0.3142\n",
            "Epoch 23/100\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3260 - val_loss: 0.3336\n",
            "Epoch 24/100\n",
            "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3261 - val_loss: 0.3113\n",
            "Epoch 25/100\n",
            "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3257 - val_loss: 0.3303\n",
            "Epoch 26/100\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3251 - val_loss: 0.3688\n",
            "Epoch 27/100\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3254 - val_loss: 0.3114\n",
            "Epoch 28/100\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3245 - val_loss: 0.3435\n",
            "Epoch 29/100\n",
            "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3244 - val_loss: 0.3325\n",
            "Epoch 30/100\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3240 - val_loss: 0.3156\n",
            "Epoch 31/100\n",
            "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3236 - val_loss: 0.3637\n",
            "Epoch 32/100\n",
            "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3236 - val_loss: 0.3121\n",
            "Epoch 33/100\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3232 - val_loss: 0.3133\n",
            "Epoch 34/100\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3228 - val_loss: 0.3210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4Pv5exHjjrz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "103cdd77-a8bc-43f6-ee53-e3f72a6013ae"
      },
      "source": [
        "plt.plot(pd.DataFrame(history_2.history))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niETE/wdYzF5p1jBJdwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgufXJS5kNmB",
        "colab_type": "text"
      },
      "source": [
        "If you need extra control, you can easily write your own custom callbacks. As an example of how to do that, the following custom callback will display the ratio between the validation loss and the training loss during training (e.g., to detect overfitting):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3H4-lRTkMIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u9rKrN_kl7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "75858dd2-0ed3-46fe-a02a-c0d28e572dfc"
      },
      "source": [
        "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
        "\n",
        "history_3 = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[val_train_ratio_cb])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/10\n",
            "11392/11610 [============================>.] - ETA: 0s - loss: 0.3242\n",
            "val/train: 0.98\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3255 - val_loss: 0.3175\n",
            "Epoch 2/10\n",
            "11232/11610 [============================>.] - ETA: 0s - loss: 0.3252\n",
            "val/train: 0.96\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3252 - val_loss: 0.3122\n",
            "Epoch 3/10\n",
            "10816/11610 [==========================>...] - ETA: 0s - loss: 0.3262\n",
            "val/train: 0.97\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3247 - val_loss: 0.3138\n",
            "Epoch 4/10\n",
            "11488/11610 [============================>.] - ETA: 0s - loss: 0.3254\n",
            "val/train: 0.96\n",
            "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3244 - val_loss: 0.3124\n",
            "Epoch 5/10\n",
            "11200/11610 [===========================>..] - ETA: 0s - loss: 0.3260\n",
            "val/train: 0.96\n",
            "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3241 - val_loss: 0.3097\n",
            "Epoch 6/10\n",
            "10656/11610 [==========================>...] - ETA: 0s - loss: 0.3243\n",
            "val/train: 1.07\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3239 - val_loss: 0.3480\n",
            "Epoch 7/10\n",
            "10880/11610 [===========================>..] - ETA: 0s - loss: 0.3257\n",
            "val/train: 1.01\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3235 - val_loss: 0.3272\n",
            "Epoch 8/10\n",
            "11392/11610 [============================>.] - ETA: 0s - loss: 0.3244\n",
            "val/train: 1.29\n",
            "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3235 - val_loss: 0.4174\n",
            "Epoch 9/10\n",
            "10912/11610 [===========================>..] - ETA: 0s - loss: 0.3223\n",
            "val/train: 0.96\n",
            "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3235 - val_loss: 0.3120\n",
            "Epoch 10/10\n",
            "10624/11610 [==========================>...] - ETA: 0s - loss: 0.3208\n",
            "val/train: 1.00\n",
            "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3227 - val_loss: 0.3234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1AFIZ5ek7fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}