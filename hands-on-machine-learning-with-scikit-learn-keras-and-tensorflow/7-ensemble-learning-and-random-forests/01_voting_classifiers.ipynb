{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-voting-classifiers.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPTt/S4iOFooTulHXwUFmlL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/machine-learning-research-and-practice/blob/main/hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow/7-ensemble-learning-and-random-forests/01_voting_classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Voting Classifiers"
      ],
      "metadata": {
        "id": "0FOcX1J5BIGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you aggregate\n",
        "the predictions of a group of predictors (such as classifiers or regressors), you will\n",
        "often get better predictions than with the best individual predictor. A group of predictors\n",
        "is called an ensemble; thus, this technique is called Ensemble Learning, and an\n",
        "Ensemble Learning algorithm is called an Ensemble method.\n",
        "\n",
        "As an example of an Ensemble method, you can train a group of Decision Tree classifiers,\n",
        "each on a different random subset of the training set. To make predictions, you\n",
        "obtain the predictions of all the individual trees, then predict the class that gets the\n",
        "most votes.\n",
        "\n",
        "Such an ensemble of Decision Trees is\n",
        "called a Random Forest, and despite its simplicity, this is one of the most powerful\n",
        "Machine Learning algorithms available today."
      ],
      "metadata": {
        "id": "6bGGszxqGWTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "uNdW10-LGl8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "metadata": {
        "id": "lfCtLHkEGm33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "1K2qktRwHGL-"
      }
    }
  ]
}