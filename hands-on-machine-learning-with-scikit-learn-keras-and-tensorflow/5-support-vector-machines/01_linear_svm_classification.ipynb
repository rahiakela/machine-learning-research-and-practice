{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-linear-svm-classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNHY93X2jwvFvLhQViLsFDV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/machine-learning-research-and-practice/blob/main/hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow/5-support-vector-machines/01_linear_svm_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Linear SVM Classification"
      ],
      "metadata": {
        "id": "1PbMfC4sPgyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Support Vector Machine (SVM) is a powerful and versatile Machine Learning\n",
        "model, capable of performing linear or nonlinear classification, regression, and even\n",
        "outlier detection.\n",
        "\n",
        "SVMs are particularly\n",
        "well suited for classification of complex small- or medium-sized datasets."
      ],
      "metadata": {
        "id": "HHJheg-GPhYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "B3Yy8AM2PwHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "metadata": {
        "id": "mTusPrAIPxK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_svc_decision_boundary(svm_clf, xmin, xmax):\n",
        "    w = svm_clf.coef_[0]\n",
        "    b = svm_clf.intercept_[0]\n",
        "\n",
        "    # At the decision boundary, w0*x0 + w1*x1 + b = 0\n",
        "    # => x1 = -w0/w1 * x0 - b/w1\n",
        "    x0 = np.linspace(xmin, xmax, 200)\n",
        "    decision_boundary = -w[0]/w[1] * x0 - b/w[1]\n",
        "\n",
        "    margin = 1/w[1]\n",
        "    gutter_up = decision_boundary + margin\n",
        "    gutter_down = decision_boundary - margin\n",
        "\n",
        "    svs = svm_clf.support_vectors_\n",
        "    plt.scatter(svs[:, 0], svs[:, 1], s=180, facecolors='#FFAAAA')\n",
        "    plt.plot(x0, decision_boundary, \"k-\", linewidth=2)\n",
        "    plt.plot(x0, gutter_up, \"k--\", linewidth=2)\n",
        "    plt.plot(x0, gutter_down, \"k--\", linewidth=2)"
      ],
      "metadata": {
        "id": "04NEI8SMQn9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Large margin classification"
      ],
      "metadata": {
        "id": "1SqQLHD1P4T1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can think of an SVM classifier as fitting the\n",
        "widest possible street (represented by the parallel dashed lines) between the classes.\n",
        "This is called large margin classification."
      ],
      "metadata": {
        "id": "kQ7ZYr9TP7Q3"
      }
    }
  ]
}